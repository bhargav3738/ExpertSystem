{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The name of the clinic is Smile Bright Dental Clinic.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def ragResponse(file):\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    documents = TextLoader(file).load()\n",
    "   \n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(openai_api_key=API_KEY))\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    return retriever\n",
    "\n",
    "API_KEY=os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "system_prompt = (\n",
    "\"You are an assistant for question-answering tasks. \"\n",
    "\"Use the following pieces of retrieved context to answer \"\n",
    "\"the question. If you don't know the answer, say that you \"\n",
    "\"don't know. Use three sentences maximum and keep the \"\n",
    "\"answer concise.\"\n",
    "\"\\n\\n\"\n",
    "\"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "[\n",
    "(\"system\", system_prompt),\n",
    "(\"human\", \"{input}\"),\n",
    "]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "temperature=0.5,\n",
    "api_key=API_KEY\n",
    ")\n",
    "\n",
    "file =\"BusinessContext.txt\"\n",
    "# print(ragResponse(file))\n",
    "\n",
    "retriever = ragResponse(file)\n",
    "\n",
    "qa_chain=create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, qa_chain)\n",
    "\n",
    "def invoker(prompt):\n",
    "    response = rag_chain.invoke({\"input\": prompt})\n",
    "    return response[\"answer\"]\n",
    "\n",
    "invoker(\"what is the name of clinic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfodj",
   "language": "python",
   "name": "tfodj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
